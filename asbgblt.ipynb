{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d73d02bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob as gb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from ipywidgets import widgets, interactive\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense,LSTM,Conv1D,MaxPooling1D,Flatten\n",
    "from prophet import Prophet\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0e1e7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>pm25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04-02-2019 19:00</td>\n",
       "      <td>70.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04-02-2019 20:00</td>\n",
       "      <td>61.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04-02-2019 21:00</td>\n",
       "      <td>59.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04-02-2019 22:00</td>\n",
       "      <td>76.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04-02-2019 23:00</td>\n",
       "      <td>98.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33531</th>\n",
       "      <td>02-12-2022 22:00</td>\n",
       "      <td>115.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33532</th>\n",
       "      <td>02-12-2022 23:00</td>\n",
       "      <td>104.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33533</th>\n",
       "      <td>03-12-2022 00:00</td>\n",
       "      <td>110.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33534</th>\n",
       "      <td>03-12-2022 01:00</td>\n",
       "      <td>122.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33535</th>\n",
       "      <td>03-12-2022 02:00</td>\n",
       "      <td>122.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33536 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Date    pm25\n",
       "0      04-02-2019 19:00   70.52\n",
       "1      04-02-2019 20:00   61.39\n",
       "2      04-02-2019 21:00   59.94\n",
       "3      04-02-2019 22:00   76.44\n",
       "4      04-02-2019 23:00   98.54\n",
       "...                 ...     ...\n",
       "33531  02-12-2022 22:00  115.37\n",
       "33532  02-12-2022 23:00  104.06\n",
       "33533  03-12-2022 00:00  110.59\n",
       "33534  03-12-2022 01:00  122.87\n",
       "33535  03-12-2022 02:00  122.71\n",
       "\n",
       "[33536 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"Ankleshwar.csv\")\n",
    "df1=df.iloc[:,1:]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cd7b61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Subham\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 560. MiB for an array with shape (51, 51, 28242) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m series = df1[\u001b[33m'\u001b[39m\u001b[33mpm25_scaled\u001b[39m\u001b[33m'\u001b[39m].dropna().reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     19\u001b[39m arima_model = ARIMA(series, order=(\u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)).fit()\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m sarima_model = \u001b[43mSARIMAX\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseasonal_order\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m24\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# --------------------------------------------------\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# STEP 3: Prepare Sequences\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# --------------------------------------------------\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_sequences\u001b[39m(data, window=\u001b[32m24\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:729\u001b[39m, in \u001b[36mMLEModel.fit\u001b[39m\u001b[34m(self, start_params, transformed, includes_fixed, cov_type, cov_kwds, method, maxiter, full_output, disp, callback, return_params, optim_score, optim_complex_step, optim_hessian, flags, low_memory, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    728\u001b[39m     func = \u001b[38;5;28mself\u001b[39m.smooth\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlefit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformed\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincludes_fixed\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m           \u001b[49m\u001b[43mcov_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcov_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov_kwds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcov_kwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    732\u001b[39m res.mlefit = mlefit\n\u001b[32m    733\u001b[39m res.mle_retvals = mlefit.mle_retvals\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:887\u001b[39m, in \u001b[36mMLEModel.smooth\u001b[39m\u001b[34m(self, params, transformed, includes_fixed, complex_step, cov_type, cov_kwds, return_ssm, results_class, results_wrapper_class, **kwargs)\u001b[39m\n\u001b[32m    884\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33minversion_method\u001b[39m\u001b[33m'\u001b[39m] = INVERT_UNIVARIATE | SOLVE_LU\n\u001b[32m    886\u001b[39m \u001b[38;5;66;03m# Get the state space output\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssm\u001b[49m\u001b[43m.\u001b[49m\u001b[43msmooth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomplex_step\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomplex_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[38;5;66;03m# Wrap in a results object\u001b[39;00m\n\u001b[32m    890\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wrap_results(params, result, return_ssm, cov_type,\n\u001b[32m    891\u001b[39m                           cov_kwds, results_class,\n\u001b[32m    892\u001b[39m                           results_wrapper_class)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\tsa\\statespace\\kalman_smoother.py:419\u001b[39m, in \u001b[36mKalmanSmoother.smooth\u001b[39m\u001b[34m(self, smoother_output, smooth_method, results, run_filter, prefix, complex_step, update_representation, update_filter, update_smoother, **kwargs)\u001b[39m\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m smoother_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    418\u001b[39m     smoother_output = \u001b[38;5;28mself\u001b[39m.smoother_output\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m smoother = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_smooth\u001b[49m\u001b[43m(\u001b[49m\u001b[43msmoother_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;66;03m# Update the results\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m update_smoother:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\tsa\\statespace\\kalman_smoother.py:355\u001b[39m, in \u001b[36mKalmanSmoother._smooth\u001b[39m\u001b[34m(self, smoother_output, smooth_method, prefix, complex_step, results, **kwargs)\u001b[39m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_smooth\u001b[39m(\u001b[38;5;28mself\u001b[39m, smoother_output=\u001b[38;5;28;01mNone\u001b[39;00m, smooth_method=\u001b[38;5;28;01mNone\u001b[39;00m, prefix=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    352\u001b[39m             complex_step=\u001b[38;5;28;01mFalse\u001b[39;00m, results=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    353\u001b[39m     \u001b[38;5;66;03m# Initialize the smoother\u001b[39;00m\n\u001b[32m    354\u001b[39m     prefix, dtype, create_smoother, create_filter, create_statespace = (\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initialize_smoother\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m            \u001b[49m\u001b[43msmoother_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmooth_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    359\u001b[39m     \u001b[38;5;66;03m# Check that the filter and statespace weren't just recreated\u001b[39;00m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m create_filter \u001b[38;5;129;01mor\u001b[39;00m create_statespace:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\tsa\\statespace\\kalman_smoother.py:179\u001b[39m, in \u001b[36mKalmanSmoother._initialize_smoother\u001b[39m\u001b[34m(self, smoother_output, smooth_method, prefix, **kwargs)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m create_smoother:\n\u001b[32m    177\u001b[39m     \u001b[38;5;66;03m# Setup the smoother\u001b[39;00m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28mcls\u001b[39m = \u001b[38;5;28mself\u001b[39m.prefix_kalman_smoother_map[prefix]\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     \u001b[38;5;28mself\u001b[39m._kalman_smoothers[prefix] = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_statespaces\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_kalman_filters\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[43msmoother_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmooth_method\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[38;5;66;03m# Otherwise, update the smoother parameters\u001b[39;00m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    185\u001b[39m     \u001b[38;5;28mself\u001b[39m._kalman_smoothers[prefix].set_smoother_output(\n\u001b[32m    186\u001b[39m         smoother_output, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mstatsmodels/tsa/statespace/_kalman_smoother.pyx:964\u001b[39m, in \u001b[36mstatsmodels.tsa.statespace._kalman_smoother.dKalmanSmoother.__init__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mstatsmodels/tsa/statespace/_kalman_smoother.pyx:1134\u001b[39m, in \u001b[36mstatsmodels.tsa.statespace._kalman_smoother.dKalmanSmoother.set_smoother_output\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mstatsmodels/tsa/statespace/_kalman_smoother.pyx:1168\u001b[39m, in \u001b[36mstatsmodels.tsa.statespace._kalman_smoother.dKalmanSmoother.reset\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mstatsmodels/tsa/statespace/_kalman_smoother.pyx:1121\u001b[39m, in \u001b[36mstatsmodels.tsa.statespace._kalman_smoother.dKalmanSmoother.reset_filter_method\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mstatsmodels/tsa/statespace/_kalman_smoother.pyx:1004\u001b[39m, in \u001b[36mstatsmodels.tsa.statespace._kalman_smoother.dKalmanSmoother.allocate_arrays\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 560. MiB for an array with shape (51, 51, 28242) and data type float64"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from statsmodels.tsa.arima.model import ARIMA\n",
    "# from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from tensorflow.keras import layers, models\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # STEP 1: Preprocess and Scale\n",
    "# # --------------------------------------------------\n",
    "# df1 = df1.drop(columns=['Timestamp', 'Hour', 'Month'])\n",
    "scaler = MinMaxScaler()\n",
    "df1['pm25_scaled'] = scaler.fit_transform(df1[['pm25']])\n",
    "\n",
    "# --------------------------------------------------\n",
    "# STEP 2: Train ARIMA & SARIMA\n",
    "# --------------------------------------------------\n",
    "series = df1['pm25_scaled'].dropna().reset_index(drop=True)\n",
    "arima_model = ARIMA(series, order=(2, 1, 2)).fit()\n",
    "sarima_model = SARIMAX(series, order=(1,1,1), seasonal_order=(1,1,1,24)).fit()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# STEP 3: Prepare Sequences\n",
    "# --------------------------------------------------\n",
    "def create_sequences(data, window=24):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window):\n",
    "        if not np.isnan(data[i + window]):\n",
    "            seq = data[i:i+window]\n",
    "            if not np.any(np.isnan(seq)):\n",
    "                X.append(seq)\n",
    "                y.append(data[i + window])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window = 24\n",
    "pm25_array = df1['pm25_scaled'].values\n",
    "X_seq, y_seq = create_sequences(pm25_array, window)\n",
    "X_seq = X_seq.reshape((X_seq.shape[0], window, 1))\n",
    "\n",
    "# --------------------------------------------------\n",
    "# STEP 4: Train BiGRU\n",
    "# --------------------------------------------------\n",
    "bigru_model = models.Sequential([\n",
    "    layers.Bidirectional(layers.GRU(64), input_shape=(window, 1)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "bigru_model.compile(optimizer='adam', loss='mse')\n",
    "bigru_model.fit(X_seq, y_seq, epochs=20, batch_size=32, verbose=1)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# STEP 5: Train BiLSTM\n",
    "# --------------------------------------------------\n",
    "bilstm_model = models.Sequential([\n",
    "    layers.Bidirectional(layers.LSTM(64), input_shape=(window, 1)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "bilstm_model.compile(optimizer='adam', loss='mse')\n",
    "bilstm_model.fit(X_seq, y_seq, epochs=20, batch_size=32, verbose=1)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# STEP 6: Train Transformer\n",
    "# --------------------------------------------------\n",
    "def transformer_block(inputs, head_size=64, num_heads=2, ff_dim=64):\n",
    "    x = layers.LayerNormalization()(inputs)\n",
    "    x = layers.MultiHeadAttention(num_heads=num_heads, key_dim=head_size)(x, x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Add()([x, inputs])\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    x = layers.Dense(ff_dim, activation='relu')(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    return layers.Add()([x, inputs])\n",
    "\n",
    "def build_transformer(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = transformer_block(inputs)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "transformer_model = build_transformer((window, 1))\n",
    "transformer_model.compile(optimizer='adam', loss='mse')\n",
    "transformer_model.fit(X_seq, y_seq, epochs=20, batch_size=32, verbose=1)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# STEP 7: Hybrid Imputation\n",
    "# --------------------------------------------------\n",
    "filled = df1['pm25_scaled'].copy()\n",
    "\n",
    "for i in range(window, len(filled)):\n",
    "    if np.isnan(filled[i]):\n",
    "        context = filled[i - window:i]\n",
    "        if not np.any(np.isnan(context)):\n",
    "            input_seq = np.array(context).reshape((1, window, 1))\n",
    "\n",
    "            pred_arima = arima_model.predict(start=i, end=i).iloc[0]\n",
    "            pred_sarima = sarima_model.predict(start=i, end=i).iloc[0]\n",
    "            pred_bigru = bigru_model.predict(input_seq, verbose=0)[0, 0]\n",
    "            pred_bilstm = bilstm_model.predict(input_seq, verbose=0)[0, 0]\n",
    "            pred_transformer = transformer_model.predict(input_seq, verbose=0)[0, 0]\n",
    "\n",
    "            final_pred = (\n",
    "                0.2 * pred_arima +\n",
    "                0.2 * pred_sarima +\n",
    "                0.2 * pred_bigru +\n",
    "                0.2 * pred_bilstm +\n",
    "                0.2 * pred_transformer\n",
    "            )\n",
    "            filled[i] = final_pred\n",
    "\n",
    "# --------------------------------------------------\n",
    "# STEP 8: Inverse Scale and Save\n",
    "# --------------------------------------------------\n",
    "df1['pm25_hybrid_bidir'] = scaler.inverse_transform(np.array(filled).reshape(-1, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
