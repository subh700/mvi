{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d73d02bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob as gb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from ipywidgets import widgets, interactive\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense,LSTM,Conv1D,MaxPooling1D,Flatten\n",
    "from prophet import Prophet\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0e1e7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>pm25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04-02-2019 19:00</td>\n",
       "      <td>70.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04-02-2019 20:00</td>\n",
       "      <td>61.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04-02-2019 21:00</td>\n",
       "      <td>59.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04-02-2019 22:00</td>\n",
       "      <td>76.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04-02-2019 23:00</td>\n",
       "      <td>98.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33531</th>\n",
       "      <td>02-12-2022 22:00</td>\n",
       "      <td>115.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33532</th>\n",
       "      <td>02-12-2022 23:00</td>\n",
       "      <td>104.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33533</th>\n",
       "      <td>03-12-2022 00:00</td>\n",
       "      <td>110.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33534</th>\n",
       "      <td>03-12-2022 01:00</td>\n",
       "      <td>122.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33535</th>\n",
       "      <td>03-12-2022 02:00</td>\n",
       "      <td>122.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33536 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Date    pm25\n",
       "0      04-02-2019 19:00   70.52\n",
       "1      04-02-2019 20:00   61.39\n",
       "2      04-02-2019 21:00   59.94\n",
       "3      04-02-2019 22:00   76.44\n",
       "4      04-02-2019 23:00   98.54\n",
       "...                 ...     ...\n",
       "33531  02-12-2022 22:00  115.37\n",
       "33532  02-12-2022 23:00  104.06\n",
       "33533  03-12-2022 00:00  110.59\n",
       "33534  03-12-2022 01:00  122.87\n",
       "33535  03-12-2022 02:00  122.71\n",
       "\n",
       "[33536 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"Ankleshwar.csv\")\n",
    "df1=df.iloc[:,1:]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cd7b61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Subham\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 6.3166e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 6.1505e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 6.4907e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 6.0780e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 5.0971e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 6.1341e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 6.5219e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 5.4400e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 6.4398e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 5.8152e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 5.2117e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 6.3669e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 6.1312e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 5.6480e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 7.1061e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 5.2308e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 5.5645e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 5.1619e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 6.8873e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 5.0352e-04\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------\n",
    "# STEP 2: Scale and Train ARIMA and SARIMA\n",
    "# --------------------------------------------------\n",
    "scaler = MinMaxScaler()\n",
    "df1['pm25_scaled'] = scaler.fit_transform(df1[['pm25']])\n",
    "series = df1['pm25_scaled'].dropna().reset_index(drop=True)\n",
    "\n",
    "arima_model = ARIMA(series, order=(3,1,2)).fit()\n",
    "sarima_model = SARIMAX(series, order=(2,1,2), seasonal_order=(1,1,1,24)).fit()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# STEP 3: Train Transformer\n",
    "# --------------------------------------------------\n",
    "def create_sequences(data, window=24):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window):\n",
    "        if not np.isnan(data[i + window]):\n",
    "            seq = data[i:i+window]\n",
    "            if not np.any(np.isnan(seq)):\n",
    "                X.append(seq)\n",
    "                y.append(data[i + window])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "pm25_array = df1['pm25_scaled'].values\n",
    "window = 24\n",
    "X, y = create_sequences(pm25_array, window)\n",
    "X = X.reshape((X.shape[0], window, 1))\n",
    "\n",
    "def transformer_block(inputs, head_size, num_heads, ff_dim, dropout=0.1):\n",
    "    x = layers.LayerNormalization()(inputs)\n",
    "    x = layers.MultiHeadAttention(num_heads=num_heads, key_dim=head_size, dropout=dropout)(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Add()([x, inputs])\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    x = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    return layers.Add()([x, inputs])\n",
    "\n",
    "def build_transformer(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = transformer_block(inputs, 64, 2, 64)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "transformer = build_transformer((window, 1))\n",
    "transformer.compile(optimizer='adam', loss='mse')\n",
    "transformer.fit(X, y, epochs=20, batch_size=32, verbose=1)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# STEP 4: Impute Missing Values\n",
    "# --------------------------------------------------\n",
    "filled = df1['pm25_scaled'].copy()\n",
    "\n",
    "for i in range(window, len(filled)):\n",
    "    if np.isnan(filled[i]):\n",
    "        context = filled[i - window:i]\n",
    "        if not np.any(np.isnan(context)):\n",
    "            input_seq = np.array(context).reshape((1, window, 1))\n",
    "\n",
    "            pred_arima = arima_model.predict(start=i, end=i).iloc[0]\n",
    "            pred_sarima = sarima_model.predict(start=i, end=i).iloc[0]\n",
    "            pred_transformer = transformer.predict(input_seq, verbose=0)[0, 0]\n",
    "\n",
    "            # Weighted ensemble\n",
    "            combined_pred = (0.3 * pred_arima + 0.3 * pred_sarima + 0.4 * pred_transformer)\n",
    "            filled[i] = combined_pred\n",
    "\n",
    "# --------------------------------------------------\n",
    "# STEP 5: Inverse Transform and Save\n",
    "# --------------------------------------------------\n",
    "df1['pm25_hybrid_arima_sarima_transformer'] = scaler.inverse_transform(filled.values.reshape(-1, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
